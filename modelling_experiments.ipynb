{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8ir2J7xItAj",
        "outputId": "e74f9fe2-bd5d-4b36-bd0e-7bf91a3d7824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scispacy\n",
            "  Downloading scispacy-0.5.3-py3-none-any.whl (45 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m41.0/45.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m972.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from scispacy) (3.6.1)\n",
            "Collecting scipy<1.11 (from scispacy)\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scispacy) (2.31.0)\n",
            "Collecting conllu (from scispacy)\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scispacy) (1.23.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scispacy) (1.3.2)\n",
            "Collecting nmslib>=1.7.3.6 (from scispacy)\n",
            "  Downloading nmslib-2.1.1.tar.gz (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from scispacy) (1.2.2)\n",
            "Collecting pysbd (from scispacy)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybind11<2.6.2 (from nmslib>=1.7.3.6->scispacy)\n",
            "  Using cached pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from nmslib>=1.7.3.6->scispacy) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (2023.11.17)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.3->scispacy) (3.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (4.66.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->scispacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->scispacy) (4.5.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->scispacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->scispacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->scispacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->scispacy) (2.1.3)\n",
            "Building wheels for collected packages: nmslib\n",
            "  Building wheel for nmslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nmslib: filename=nmslib-2.1.1-cp310-cp310-linux_x86_64.whl size=13547971 sha256=d2a019f5ead05f5001cdae75fb7fcd840333005e495c8950c8f8812e583217ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/1a/5d/4cc754a5b1a88405cad184b76f823897a63a8d19afcd4b9314\n",
            "Successfully built nmslib\n",
            "Installing collected packages: scipy, pysbd, pybind11, conllu, nmslib, scispacy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed conllu-4.5.3 nmslib-2.1.1 pybind11-2.6.1 pysbd-0.3.4 scipy-1.10.1 scispacy-0.5.3\n",
            "Collecting spacy==3.2\n",
            "  Downloading spacy-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (3.0.9)\n",
            "Collecting thinc<8.1.0,>=8.0.12 (from spacy==3.2)\n",
            "  Downloading thinc-8.0.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (659 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m659.5/659.5 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (0.7.11)\n",
            "Collecting wasabi<1.1.0,>=0.8.1 (from spacy==3.2)\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (2.0.10)\n",
            "Collecting typer<0.5.0,>=0.3.0 (from spacy==3.2)\n",
            "  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (0.10.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (2.31.0)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 (from spacy==3.2)\n",
            "  Downloading pydantic-1.8.2-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2) (3.3.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy==3.2) (6.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy==3.2) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2) (2023.11.17)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.2) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.2) (2.1.3)\n",
            "Installing collected packages: wasabi, typer, pydantic, thinc, spacy\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.2\n",
            "    Uninstalling wasabi-1.1.2:\n",
            "      Successfully uninstalled wasabi-1.1.2\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.0\n",
            "    Uninstalling typer-0.9.0:\n",
            "      Successfully uninstalled typer-0.9.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.12\n",
            "    Uninstalling thinc-8.1.12:\n",
            "      Successfully uninstalled thinc-8.1.12\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.6.1\n",
            "    Uninstalling spacy-3.6.1:\n",
            "      Successfully uninstalled spacy-3.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "en-core-web-sm 3.6.0 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.2.0 which is incompatible.\n",
            "inflect 7.0.0 requires pydantic>=1.9.1, but you have pydantic 1.8.2 which is incompatible.\n",
            "scispacy 0.5.3 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pydantic-1.8.2 spacy-3.2.0 thinc-8.0.17 typer-0.4.2 wasabi-0.10.1\n",
            "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bc5cdr_md-0.4.0.tar.gz\n",
            "  Downloading https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bc5cdr_md-0.4.0.tar.gz (125.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.1/125.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spacy<3.1.0,>=3.0.1 (from en-ner-bc5cdr-md==0.4.0)\n",
            "  Downloading spacy-3.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (3.0.12)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (0.7.11)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (2.0.10)\n",
            "Collecting typer<0.4.0,>=0.3.0 (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0)\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (2023.11.17)\n",
            "Collecting click<7.2.0,>=7.1.1 (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0)\n",
            "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.1.0,>=3.0.1->en-ner-bc5cdr-md==0.4.0) (2.1.3)\n",
            "Building wheels for collected packages: en-ner-bc5cdr-md\n",
            "  Building wheel for en-ner-bc5cdr-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-ner-bc5cdr-md: filename=en_ner_bc5cdr_md-0.4.0-py3-none-any.whl size=125666862 sha256=0d20624179cc6499c4954e015f83c38e2bdb981aed9e00903d6d3273ee225e74\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/f5/32/313d08b812c91abeb6fb1d3b0f8fd69687c30c3a9d38288e4c\n",
            "Successfully built en-ner-bc5cdr-md\n",
            "Installing collected packages: click, typer, spacy, en-ner-bc5cdr-md\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.7\n",
            "    Uninstalling click-8.1.7:\n",
            "      Successfully uninstalled click-8.1.7\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.4.2\n",
            "    Uninstalling typer-0.4.2:\n",
            "      Successfully uninstalled typer-0.4.2\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.2.0\n",
            "    Uninstalling spacy-3.2.0:\n",
            "      Successfully uninstalled spacy-3.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "flask 2.2.5 requires click>=8.0, but you have click 7.1.2 which is incompatible.\n",
            "dask 2023.8.1 requires click>=8.0, but you have click 7.1.2 which is incompatible.\n",
            "distributed 2023.8.1 requires click>=8.0, but you have click 7.1.2 which is incompatible.\n",
            "en-core-web-sm 3.6.0 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.0.9 which is incompatible.\n",
            "fiona 1.9.5 requires click~=8.0, but you have click 7.1.2 which is incompatible.\n",
            "pip-tools 6.13.0 requires click>=8, but you have click 7.1.2 which is incompatible.\n",
            "scispacy 0.5.3 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.0.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed click-7.1.2 en-ner-bc5cdr-md-0.4.0 spacy-3.0.9 typer-0.3.2\n",
            "Collecting en_core_web_sm\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0.tar.gz (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spacy<3.5.0,>=3.4.0 (from en_core_web_sm)\n",
            "  Downloading spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (3.0.9)\n",
            "Collecting thinc<8.2.0,>=8.1.0 (from spacy<3.5.0,>=3.4.0->en_core_web_sm)\n",
            "  Downloading thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m919.6/919.6 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (2.0.10)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (0.3.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.0->en_core_web_sm) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en_core_web_sm) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en_core_web_sm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en_core_web_sm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en_core_web_sm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en_core_web_sm) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en_core_web_sm) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en_core_web_sm) (0.1.4)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en_core_web_sm) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en_core_web_sm) (2.1.3)\n",
            "Building wheels for collected packages: en_core_web_sm\n",
            "  Building wheel for en_core_web_sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en_core_web_sm: filename=en_core_web_sm-3.4.0-py3-none-any.whl size=12803012 sha256=05da31b905ae40a9e87cbaba46a855eb9a393ce611fd07694d504a4412e223e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/7c/52/87b6e1bfdc0066764271ae0269b8bb1578147e84e984f0e0a6\n",
            "Successfully built en_core_web_sm\n",
            "Installing collected packages: thinc, spacy, en_core_web_sm\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.0.17\n",
            "    Uninstalling thinc-8.0.17:\n",
            "      Successfully uninstalled thinc-8.0.17\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.0.9\n",
            "    Uninstalling spacy-3.0.9:\n",
            "      Successfully uninstalled spacy-3.0.9\n",
            "  Attempting uninstall: en_core_web_sm\n",
            "    Found existing installation: en-core-web-sm 3.6.0\n",
            "    Uninstalling en-core-web-sm-3.6.0:\n",
            "      Successfully uninstalled en-core-web-sm-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-ner-bc5cdr-md 0.4.0 requires spacy<3.1.0,>=3.0.1, but you have spacy 3.4.4 which is incompatible.\n",
            "scispacy 0.5.3 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.4.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed en_core_web_sm-3.4.0 spacy-3.4.4 thinc-8.1.12\n"
          ]
        }
      ],
      "source": [
        "#!pip install scispacy\n",
        "#!pip install spacy==3.2\n",
        "#!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bc5cdr_md-0.4.0.tar.gz\n",
        "#!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0.tar.gz#egg=en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k72cA7T3KbJj",
        "outputId": "7a69c625-ba92-4660-bb3b-ea2bd8140daf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6Z1bIayMftO",
        "outputId": "f82c76fc-1a11-4b1d-ad6d-5109352dadf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "# device = torch.device(\"cpu\")\n",
        "# TODO: Uncomment the below line if you see True in the print statement\n",
        "device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz4vCO2xIwp5",
        "outputId": "6e59a233-9409-47ac-fe06-e248ba45050c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:877: UserWarning: [W095] Model 'en_ner_bc5cdr_md' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.4.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import scispacy\n",
        "import spacy\n",
        "import json\n",
        "import spacy.cli\n",
        "nlp = spacy.load(\"en_ner_bc5cdr_md\")\n",
        "import os\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from typing import Dict, List"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read train json and CTR files"
      ],
      "metadata": {
        "id": "CtxxkbNMXncC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hk98jXvUovCQ"
      },
      "outputs": [],
      "source": [
        "path_to_CT_json = \"drive/MyDrive/training_data/CT json/\"\n",
        "file_name_to_CT_dict = {}  #eg : {'NCT00001832':{---CT json---}}\n",
        "\n",
        "json_file_names = [filename for filename in os.listdir(path_to_CT_json) if filename.endswith('.json')]\n",
        "for json_file_name in json_file_names:\n",
        "    with open(os.path.join(path_to_CT_json, json_file_name)) as json_file:\n",
        "        json_text = json.load(json_file)\n",
        "        file_name_to_CT_dict[json_file_name[:-5]]= json_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hoL_4VYrg3bH"
      },
      "outputs": [],
      "source": [
        "train_path = \"drive/MyDrive/training_data/train.json\"\n",
        "with open(train_path) as json_file:\n",
        "    train = json.load(json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PqzSqjtKA7tY"
      },
      "outputs": [],
      "source": [
        "test_path = \"drive/MyDrive/training_data/dev.json\"\n",
        "with open(test_path) as json_file:\n",
        "    test = json.load(json_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the text summarizer module"
      ],
      "metadata": {
        "id": "aFDy2_lwX9IE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"Falconsai/medical_summarization\", device = 0)\n",
        "\n",
        "\n",
        "def get_summarized_text(MEDICAL_DOCUMENT):\n",
        "  return summarizer(MEDICAL_DOCUMENT, max_length=150, min_length=30, do_sample=False)[0]['summary_text']"
      ],
      "metadata": {
        "id": "AKQCzf1QylqJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert json files to single dict"
      ],
      "metadata": {
        "id": "SQpf602QYInO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "icI0ZsfgktAD"
      },
      "outputs": [],
      "source": [
        "label_map = {\"Contradiction\":0,\"Entailment\":1}\n",
        "def convert_to_dataset(json_data):\n",
        "  dataset = []\n",
        "  for i in json_data.keys():\n",
        "    d ={}\n",
        "    d['label'] = label_map[json_data[i][\"Label\"]]\n",
        "    section_id = json_data[i][\"Section_id\"]\n",
        "\n",
        "    d['hypothesis'] = json_data[i][\"Statement\"]\n",
        "\n",
        "    primary_ct = file_name_to_CT_dict[(json_data[i][\"Primary_id\"])]\n",
        "\n",
        "    if len(primary_ct[section_id]) > 512:\n",
        "      print(\"greater\")\n",
        "      updated_primary_ct = get_summarized_text(\" \".join(primary_ct[section_id]))\n",
        "      d['primary_premise'] = updated_primary_ct\n",
        "    else:\n",
        "      d['primary_premise'] = \" \".join(primary_ct[section_id])\n",
        "\n",
        "    d['secondary_premise'] = \"\"\n",
        "\n",
        "    if(\"Secondary_id\" in json_data[i].keys()):\n",
        "      secondary_ct = file_name_to_CT_dict[json_data[i][\"Secondary_id\"]]\n",
        "\n",
        "      if len(secondary_ct[section_id]) > 512:\n",
        "        updated_secondary_ct = get_summarized_text(\" \".join(secondary_ct[section_id]))\n",
        "        d['secondary_premise'] = updated_secondary_ct\n",
        "      else:\n",
        "        d['secondary_premise'] = \" \".join(secondary_ct[section_id])\n",
        "\n",
        "    dataset.append(d)\n",
        "\n",
        "  return dataset\n",
        "\n",
        "train_validate_dataset = convert_to_dataset(train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iAAVRahHAUzQ"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_validate_dataset[:1500]\n",
        "validation_dataset = train_validate_dataset[1500:]\n",
        "test_dataset = convert_to_dataset(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Preprocessing"
      ],
      "metadata": {
        "id": "EcSVy9mKYUMr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1XLAFQx_TY6",
        "outputId": "94bde356-1141-4b59-cb8b-f9446422dbe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a sample sentence with minus between words but not followed by numbers. - 2 / 3  2 mg/g  100 g gw 100 3 bananas 100100\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "def truncate(match):\n",
        "    number = float(match.group(0))\n",
        "    truncated_number = round(number, 1)\n",
        "    return str(truncated_number)\n",
        "\n",
        "def replace_custom_punctuations_with_space(input_string, custom_punctuations):\n",
        "    pattern = '[' + re.escape(''.join(custom_punctuations)) + ']'\n",
        "    result = re.sub(pattern, ' ', input_string)\n",
        "    return result\n",
        "\n",
        "def replace_slash_between_number_and_word(input_string):\n",
        "    pattern = r'(?<=\\d)/(?=\\w)'\n",
        "    result = re.sub(pattern, ' ', input_string)\n",
        "    return result\n",
        "\n",
        "def add_space_between_word_and_number(input_string):\n",
        "    pattern = re.compile(r'([a-zA-Z]+)(\\d+)')\n",
        "    result = re.sub(pattern, r'\\1 \\2', input_string)\n",
        "\n",
        "    # Add space between number and word\n",
        "    pattern = re.compile(r'(\\d+)([a-zA-Z]+)')\n",
        "    result = re.sub(pattern, r'\\1 \\2', result)\n",
        "\n",
        "    return result\n",
        "\n",
        "def remove_comma_between_numbers(input_string):\n",
        "    pattern = re.compile(r'(\\d+),(\\d+)')\n",
        "    result = re.sub(pattern, r'\\1\\2', input_string)\n",
        "    return result\n",
        "\n",
        "def initial_preprocessing(sentence):\n",
        "\n",
        "    result = re.sub(r'(-?\\d+\\.\\d+)', truncate, sentence)\n",
        "\n",
        "    tokens = re.split( r'(?<=\\w)-(?=\\D)|(?<=\\d)(/)(?=\\d)', result)\n",
        "    tokens = [i for i in tokens if i!=None ]\n",
        "    tokens = \" \".join(tokens)\n",
        "\n",
        "    tokens = replace_slash_between_number_and_word(tokens)\n",
        "\n",
        "    tokens = add_space_between_word_and_number(tokens)\n",
        "\n",
        "    tokens = remove_comma_between_numbers(tokens)\n",
        "\n",
        "    custom_punctuations = ['(', '=', '~',')','{','}','\\\\','+','[',']']  # Add your custom punctuations to replace here\n",
        "\n",
        "    output_string = replace_custom_punctuations_with_space(tokens, custom_punctuations)\n",
        "\n",
        "    return output_string\n",
        "\n",
        "# Example usage:\n",
        "input_sentence = \"This is a sample sentence-with-minus between words but not-followed by numbers. -(2/3) 2/mg/g  100g gw100 3bananas 100,100\"\n",
        "result = initial_preprocessing(input_sentence)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "additional_stopwords = [\"achieved\", \"administered\", \"adverse\", \"better\", \"both\",\n",
        "                        \"between\", \"cannot\", \"case\", \"cases\", \"cohort\", \"cohorts\",\n",
        "                        \"common\", \"confirmed\", \"depending\", \"diagnosed\", \"did\",\n",
        "                        \"difference\", \"different\", \"do\", \"does\", \"each\", \"either\",\n",
        "                        \"eligible\", \"event\", \"events\", \"every\", \"excluded\", \"experienced\",\n",
        "                        \"group\", \"groups\", \"having\", \"higher\", \"included\", \"ineligible\",\n",
        "                        \"intervention\", \"interventions\", \"least\", \"less\", \"lower\", \"many\",\n",
        "                        \"may\", \"minimum\", \"more\", \"most\", \"must\", \"none\", \"number\",\n",
        "                        \"observed\", \"occurred\", \"one\", \"outcome\", \"over\", \"part\",\n",
        "                        \"participant\", \"participants\", \"participate\", \"participating\",\n",
        "                        \"participation\", \"patient\", \"patients\", \"primary\", \"prior\", \"receive\",\n",
        "                        \"received\", \"receiving\", \"recently\", \"record\", \"recorded\", \"reported\",\n",
        "                        \"require\", \"required\", \"requires\", \"response\", \"results\", \"same\", \"secondary\",\n",
        "                        \"several\", \"still\", \"study\", \"subjects\", \"suffered\", \"take\", \"treated\",\n",
        "                        \"treatment\", \"trial\", \"types\", \"undergo\", \"unit\", \"use\", \"used\", \"uses\",\n",
        "                        \"whereas\", \"who\", \"will\",\"would\"]"
      ],
      "metadata": {
        "id": "Jz2ikufh2QTb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oXpsP1iENZb8"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List, Optional, Tuple\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "def replace_signs(text):\n",
        "    text = text.replace(\">=\", \"greater than or equal \")\n",
        "    text = text.replace(\"=>\", \"greater than or equal \")\n",
        "    text = text.replace(\"=<\", \"less than or equal \")\n",
        "    text = text.replace(\"<=\", \"less than or equal \")\n",
        "    text = text.replace(\">\", \"greater than \")\n",
        "    text = text.replace(\"<\", \"less than \")\n",
        "\n",
        "    return text\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].lower()\n",
        "    tag_dict = {\"a\": wordnet.ADJ,\n",
        "                \"n\": wordnet.NOUN,\n",
        "                \"v\": wordnet.VERB,\n",
        "                \"r\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "def clean_text(text):\n",
        "    text = initial_preprocessing(text)\n",
        "    doc_tokenizer = nlp(replace_signs(text))\n",
        "    remove_stop_words = ([token.lemma_.strip().lower() for token in doc_tokenizer  if token.is_stop==False and token.text.strip()!=''])\n",
        "    removed_punctuations = [i for i in remove_stop_words if i not in string.punctuation]\n",
        "    preprocessed_tokens = [WordNetLemmatizer().lemmatize(i, get_wordnet_pos(i)) for i in removed_punctuations]\n",
        "    return preprocessed_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean primary premise, secondary premise and hypothesis"
      ],
      "metadata": {
        "id": "wNJx1jWjYhWl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7X8SemmnNdr8"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def tokenize(sentences: List[Dict]) -> List[List[str]]:\n",
        "\n",
        "    tokenized_sentences = []\n",
        "    i=0\n",
        "    for texts in tqdm(sentences):\n",
        "      hypothesis = texts[\"hypothesis\"]\n",
        "      primary_premise = texts[\"primary_premise\"]\n",
        "      secondary_premise = texts[\"secondary_premise\"]\n",
        "\n",
        "      #print(\"Previous\", len(hypothesis.split(\" \")), len(primary_premise.split(\" \")), len(secondary_premise.split(\" \")))\n",
        "      if len(hypothesis.split(\" \")) > 150:\n",
        "        hypothesis = get_summarized_text(hypothesis)\n",
        "\n",
        "      if len(primary_premise.split(\" \")) > 150:\n",
        "        primary_premise = get_summarized_text(primary_premise)\n",
        "\n",
        "      if len(secondary_premise.split(\" \")) > 150:\n",
        "        secondary_premise = get_summarized_text(secondary_premise)\n",
        "\n",
        "      #print(\"Updated\", len(hypothesis.split(\" \")), len(primary_premise.split(\" \")), len(secondary_premise.split(\" \")))\n",
        "      #print(\"*\"*50)\n",
        "      clean_hypothesis = clean_text(hypothesis)\n",
        "      clean_primary_premise = clean_text(primary_premise)\n",
        "      clean_secondary_premise = clean_text(secondary_premise)\n",
        "      label = texts['label']\n",
        "      '''lemmatized = clean_hypothesis+['<SEP>']+clean_primary_premise+['<SEP>']+clean_secondary_premise\n",
        "      lemmatized.append('<EOS>')\n",
        "      lemmatized.insert(0, '<SOS>')'''\n",
        "\n",
        "      lemmatized = {\"premise\": \"primary trial \" + \" \".join(clean_primary_premise) + \"secondary trial \"+ \" \".join(clean_secondary_premise), \"hypothesis\": \" \".join(clean_hypothesis), \"label\": label}\n",
        "      #lemmatized = {\"premise\": \"primary trial \" + primary_premise + \"secondary trial \"+ secondary_premise, \"hypothesis\": hypothesis, \"label\": label}\n",
        "      #tokenized_sentences.append(\" \".join(lemmatized))\n",
        "      tokenized_sentences.append(lemmatized)\n",
        "\n",
        "    return tokenized_sentences\n",
        "\n",
        "def pad(batch: List[List[str]]) -> List[List[str]]:\n",
        "    pad_symbol = \"<PAD>\"\n",
        "    max_length = max(len(i) for i in batch)\n",
        "\n",
        "    for b in range(len(batch)):\n",
        "        num_of_paddings = max_length - len(batch[b])\n",
        "        batch[b].extend([pad_symbol]*num_of_paddings)\n",
        "\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "00Ck8LVeNvtK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90428fca-75d2-4126-a162-5b4a9815ad70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/1900 [00:01<48:51,  1.54s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 512). Running this sequence through the model will result in indexing errors\n",
            "  1%|▏         | 24/1900 [00:21<17:18,  1.81it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "100%|██████████| 1900/1900 [34:13<00:00,  1.08s/it]\n"
          ]
        }
      ],
      "source": [
        "# create the vocabulary of the dataset: use both training and test sets here\n",
        "\n",
        "SPECIAL_TOKENS = ['<UNK>', '<PAD>', '<SOS>', '<EOS>']\n",
        "\n",
        "all_data = train_dataset + validation_dataset + test_dataset\n",
        "\n",
        "tokenized_data = tokenize(all_data)\n",
        "\n",
        "#vocab = sorted(set([w for ws in tokenized_data + [SPECIAL_TOKENS] for w in ws]))\n",
        "#file = open('/content/drive/MyDrive/NLP Shared Task /voacb.txt','w')\n",
        "#for item in vocab:\n",
        "\t#file.write(item+\"\\n\")\n",
        "#file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "# pip install torch torchvision transformers datasets\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import T5Tokenizer, T5ForSequenceClassification, AdamW\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, AutoModelForSeq2SeqLM\n",
        "#from datasets import load_dataset"
      ],
      "metadata": {
        "id": "cuyWpTKYFckz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch tokenizer for BioLinkBert"
      ],
      "metadata": {
        "id": "ro2AcTE_YwDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nothing to do for this class!\n",
        "\n",
        "class BatchTokenizer:\n",
        "    \"\"\"Tokenizes and pads a batch of input sentences.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name='michiyasunaga/BioLinkBERT-base'):\n",
        "        \"\"\"Initializes the tokenizer\n",
        "\n",
        "        Args:\n",
        "            pad_symbol (Optional[str], optional): The symbol for a pad. Defaults to \"<P>\".\n",
        "        \"\"\"\n",
        "        self.hf_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def get_sep_token(self,):\n",
        "        return self.hf_tokenizer.sep_token\n",
        "\n",
        "    def __call__(self, prem_batch: List[str], hyp_batch: List[str]) -> List[List[str]]:\n",
        "        \"\"\"Uses the huggingface tokenizer to tokenize and pad a batch.\n",
        "\n",
        "        We return a dictionary of tensors per the huggingface model specification.\n",
        "\n",
        "        Args:\n",
        "            batch (List[str]): A List of sentence strings\n",
        "\n",
        "        Returns:\n",
        "            Dict: The dictionary of token specifications provided by HuggingFace\n",
        "        \"\"\"\n",
        "        # The HF tokenizer will PAD for us, and additionally combine\n",
        "        # The two sentences deimited by the [SEP] token.\n",
        "        enc = self.hf_tokenizer(\n",
        "            prem_batch,\n",
        "            hyp_batch,\n",
        "            padding=True,\n",
        "            return_token_type_ids=False,\n",
        "            max_length=512,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return enc\n",
        "\n",
        "\n",
        "# HERE IS AN EXAMPLE OF HOW TO USE THE BATCH TOKENIZER\n",
        "tokenizer = BatchTokenizer()\n",
        "x = tokenizer(*[[\"this is the first premise\", \"This is the second premise\"], [\"This is first hypothesis\", \"This is the second hypothesis\"]])\n",
        "print(x)\n",
        "tokenizer.hf_tokenizer.batch_decode(x[\"input_ids\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "deDaZPxPFcrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03203c72-0ee8-4fcf-a162-df26b261bb8a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    2,  1805,  1744,  1680,  2389, 26770,     3,  1805,  1744,  2389,\n",
            "          4405,     3,     0],\n",
            "        [    2,  1805,  1744,  1680,  2702, 26770,     3,  1805,  1744,  1680,\n",
            "          2702,  4405,     3]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2632: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] this is the first premise [SEP] this is first hypothesis [SEP] [PAD]',\n",
              " '[CLS] this is the second premise [SEP] this is the second hypothesis [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_pairwise_input(dataset: List[Dict]) -> (List[str], List[str], List[int]):\n",
        "    \"\"\"\n",
        "    TODO: group all premises and corresponding hypotheses and labels of the datapoints\n",
        "    a datapoint as seen earlier is a dict of premis, hypothesis and label\n",
        "    \"\"\"\n",
        "    premises = []\n",
        "    hypothesis = []\n",
        "    labels = []\n",
        "    for x in dataset:\n",
        "        premises.append(x['premise'])\n",
        "        hypothesis.append(x['hypothesis'])\n",
        "        labels.append(x['label'])\n",
        "\n",
        "    return premises, hypothesis, labels"
      ],
      "metadata": {
        "id": "fQcI5idvop7u"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tokenized_data[0:1700]\n",
        "validation_dataset = tokenized_data[1700:]\n",
        "test_dataset = tokenized_data[1700:]"
      ],
      "metadata": {
        "id": "_qrCKOZloyuZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_premises, train_hypotheses, train_labels = generate_pairwise_input(train_dataset)\n",
        "validation_premises, validation_hypotheses, validation_labels = generate_pairwise_input(validation_dataset)\n",
        "test_premises, test_hypotheses, test_labels = generate_pairwise_input(test_dataset)"
      ],
      "metadata": {
        "id": "xwE_CUz0orli"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batching the train, validation and test data"
      ],
      "metadata": {
        "id": "E8xXTmAbZcwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "def chunk_multi(lst1, lst2, n):\n",
        "    for i in range(0, len(lst1), n):\n",
        "        yield lst1[i: i + n], lst2[i: i + n]\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "# Notice that since we use huggingface, we tokenize and\n",
        "# encode in all at once!\n",
        "tokenizer = BatchTokenizer()\n",
        "train_input_batches = [b for b in chunk_multi(train_premises, train_hypotheses, batch_size)]\n",
        "# Tokenize + encode\n",
        "train_input_batches = [tokenizer(*batch) for batch in train_input_batches]"
      ],
      "metadata": {
        "id": "_G_sjJAqpGjD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_labels(labels: List[int]) -> torch.FloatTensor:\n",
        "    \"\"\"Turns the batch of labels into a tensor\n",
        "\n",
        "    Args:\n",
        "        labels (List[int]): List of all labels in the batch\n",
        "\n",
        "    Returns:\n",
        "        torch.FloatTensor: Tensor of all labels in the batch\n",
        "    \"\"\"\n",
        "    return torch.LongTensor([int(l) for l in labels])\n",
        "\n",
        "\n",
        "train_label_batches = [b for b in chunk(train_labels, batch_size)]\n",
        "train_label_batches = [encode_labels(batch) for batch in train_label_batches]"
      ],
      "metadata": {
        "id": "rbErDTMNpJu4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLIClassfier for BioLink-Bert for fine-tuning"
      ],
      "metadata": {
        "id": "iT1SSTviZjSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NLIClassifier(torch.nn.Module):\n",
        "    def __init__(self, output_size: int, hidden_size: int, model_name='michiyasunaga/BioLinkBERT-base'):\n",
        "        super().__init__()\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Initialize BERT, which we use instead of a single embedding layer.\n",
        "        self.bert = BertModel.from_pretrained(model_name)\n",
        "\n",
        "        for param in self.bert.parameters():\n",
        "             param.requires_grad = False\n",
        "\n",
        "        self.bert_hidden_dimension = self.bert.config.hidden_size\n",
        "        self.hidden_layer = torch.nn.Linear(self.bert_hidden_dimension, self.hidden_size)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "        self.classifier = torch.nn.Linear(self.hidden_size, self.output_size)\n",
        "        self.log_softmax = torch.nn.LogSoftmax(dim=2)\n",
        "\n",
        "    def encode_text(\n",
        "        self,\n",
        "        symbols: Dict\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"Encode the (batch of) sequence(s) of token symbols BERT.\n",
        "            Then, get CLS represenation.\n",
        "\n",
        "        Args:\n",
        "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: CLS token embedding\n",
        "        \"\"\"\n",
        "\n",
        "        encoded_sequence = self.bert(**symbols)\n",
        "        cls_token = encoded_sequence.last_hidden_state[:, 0, :].unsqueeze(1)\n",
        "        return cls_token\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        symbols: Dict,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"_summary_\n",
        "\n",
        "        Args:\n",
        "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: _description_\n",
        "        \"\"\"\n",
        "        encoded_sents = self.encode_text(symbols)\n",
        "        output = self.hidden_layer(encoded_sents)\n",
        "        output = self.relu(output)\n",
        "        output = self.classifier(output)\n",
        "        return self.log_softmax(output)"
      ],
      "metadata": {
        "id": "PtUvZyU9pNKA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For making predictions at test time\n",
        "def predict(model: torch.nn.Module, sents: torch.Tensor) -> List:\n",
        "    logits = model(sents.to(device))\n",
        "    return list(torch.Tensor.cpu(torch.argmax(logits, axis=2).squeeze()).numpy())"
      ],
      "metadata": {
        "id": "zdGrjG-hpULS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Metrics"
      ],
      "metadata": {
        "id": "NR1y8Bs1aWyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import sum as t_sum\n",
        "from numpy import logical_and\n",
        "\n",
        "\n",
        "def precision(predicted_labels, true_labels, which_label=1):\n",
        "    \"\"\"\n",
        "    Precision is True Positives / All Positives Predictions\n",
        "    \"\"\"\n",
        "    pred_which = np.array([pred == which_label for pred in predicted_labels])\n",
        "    true_which = np.array([lab == which_label for lab in true_labels])\n",
        "    denominator = t_sum(pred_which)\n",
        "    if denominator:\n",
        "        return t_sum(logical_and(pred_which, true_which))/denominator\n",
        "    else:\n",
        "        return 0.\n",
        "\n",
        "\n",
        "def recall(predicted_labels, true_labels, which_label=1):\n",
        "    \"\"\"\n",
        "    Recall is True Positives / All Positive Labels\n",
        "    \"\"\"\n",
        "    pred_which = np.array([pred == which_label for pred in predicted_labels])\n",
        "    true_which = np.array([lab == which_label for lab in true_labels])\n",
        "    denominator = t_sum(true_which)\n",
        "    if denominator:\n",
        "        return t_sum(logical_and(pred_which, true_which))/denominator\n",
        "    else:\n",
        "        return 0.\n",
        "\n",
        "\n",
        "def f1_score(\n",
        "    predicted_labels: List[int],\n",
        "    true_labels: List[int],\n",
        "    which_label: int\n",
        "):\n",
        "    \"\"\"\n",
        "    F1 score is the harmonic mean of precision and recall\n",
        "    \"\"\"\n",
        "    P = precision(predicted_labels, true_labels, which_label=which_label)\n",
        "    R = recall(predicted_labels, true_labels, which_label=which_label)\n",
        "\n",
        "    if P and R:\n",
        "        return 2*P*R/(P+R)\n",
        "    else:\n",
        "        return 0.\n",
        "\n",
        "\n",
        "def macro_f1(\n",
        "    predicted_labels: List[int],\n",
        "    true_labels: List[int],\n",
        "    possible_labels: List[int],\n",
        "    label_map=None\n",
        "):\n",
        "    converted_prediction = [label_map[int(x)] for x in predicted_labels] if label_map else predicted_labels\n",
        "    scores = [f1_score(converted_prediction, true_labels, l) for l in possible_labels]\n",
        "    # Macro, so we take the uniform avg.\n",
        "    return sum(scores) / len(scores)\n"
      ],
      "metadata": {
        "id": "22mU23_3pVil"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "-Dq606-1PCL8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop with hyperparameters"
      ],
      "metadata": {
        "id": "P4A2-XH6abk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(\n",
        "    num_epochs,\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    dev_sents,\n",
        "    dev_labels,\n",
        "    optimizer,\n",
        "    model,\n",
        "):\n",
        "    print(\"Training...\")\n",
        "    loss_func = torch.nn.NLLLoss()\n",
        "    batches = list(zip(train_features, train_labels))\n",
        "    random.shuffle(batches)\n",
        "    f1_scores = []\n",
        "    for i in range(num_epochs):\n",
        "        losses = []\n",
        "        for features, labels in tqdm(batches):\n",
        "            # Empty the dynamic computation graph\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(features.to(device)).squeeze(1)\n",
        "            loss = loss_func(preds, labels.to(device))\n",
        "            # Backpropogate the loss through our model\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        print(f\"epoch {i}, loss: {sum(losses)/len(losses)}\")\n",
        "        # Estimate the f1 score for the development set\n",
        "        print(\"Evaluating dev...\")\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        for sents, labels in tqdm(zip(dev_sents, dev_labels), total=len(dev_sents)):\n",
        "            pred = predict(model, sents)\n",
        "            all_preds.extend(pred)\n",
        "            all_labels.extend(list(labels.cpu().numpy()))\n",
        "\n",
        "        dev_f1 = macro_f1(all_preds, all_labels, possible_labels=[0,1])\n",
        "        f1_scores.append(dev_f1)\n",
        "        print(f\"Dev F1 {dev_f1}\")\n",
        "\n",
        "    plt.plot(f1_scores)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Done training!\")\n",
        "    # Return the trained model\n",
        "    return model"
      ],
      "metadata": {
        "id": "AnFoMeBbpXuY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "import random"
      ],
      "metadata": {
        "id": "KAlEcBd_phc8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can increase epochs if need be\n",
        "epochs = 5\n",
        "\n",
        "# TODO: Find a good learning rate and hidden size\n",
        "LR = 2e-05\n",
        "hidden_size = 512\n",
        "possible_labels = set(train_labels)\n",
        "model = NLIClassifier(output_size=len(possible_labels), hidden_size=hidden_size)\n",
        "model\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), LR, weight_decay=0.1)\n",
        "\n",
        "batch_tokenizer = BatchTokenizer()\n",
        "\n",
        "validation_input_batches = [b for b in chunk_multi(validation_premises, validation_hypotheses, batch_size)]\n",
        "\n",
        "# Tokenize + encode\n",
        "validation_input_batches = [batch_tokenizer(*batch) for batch in validation_input_batches]\n",
        "validation_batch_labels = [b for b in chunk(validation_labels, batch_size)]\n",
        "validation_batch_labels = [encode_labels(batch) for batch in validation_batch_labels]\n",
        "\n",
        "training_loop(\n",
        "    epochs,\n",
        "    train_input_batches,\n",
        "    train_label_batches,\n",
        "    validation_input_batches,\n",
        "    validation_batch_labels,\n",
        "    optimizer,\n",
        "    model,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7db3e6a74b4541299d0e4ea461ed7961",
            "a63ab33da41c46fba3e9ac7b5f9ee858",
            "b9c78124a54d47b8a70f2e22be41e5d7",
            "1f045e21492f4208b4f5bf3a77edf5b3",
            "cf52c0b0629846efbdbf9cbeb269b436",
            "cb5a0d9556be45c5815c581dcf98bf9e",
            "c14a94f5b0b04f378bb6f71ba288846f",
            "4417d79fd99d45fabbaccd4bda09abeb",
            "3ba6b88df5e848279d9d48772cf8bea6",
            "08d5cbcf05e74c0289a86f9af1f81e87",
            "7160d4b7f33d4c20a7f632b87bc7ce7c",
            "4c77aae91f454055a5644d1a742f648a",
            "d370d3431dbc47bbb8aebc17da86952d",
            "a52758c82e744a13923dcdfbe4ac1deb",
            "957a94d2741b43e283a086dc34d88a45",
            "0d4063d54bd149218626eae41ec0d7db",
            "8a374ea57be646e09f074fac500d5edd",
            "e31549bb58224eb198e9ff469ba9f24d",
            "b1c5b03133134df0a995fb78a9b40b4b",
            "ea4cccea489c45238371f62f2f15b94c",
            "25b9f3396c7e420b92447fd3d1ecc328",
            "6d59dac1bdc741f69ded63cf3f5f5e2f"
          ]
        },
        "id": "mZ-JnC_5paUt",
        "outputId": "8501992f-9104-47d0-cc5a-6463a305cc34"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/559 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7db3e6a74b4541299d0e4ea461ed7961"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c77aae91f454055a5644d1a742f648a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2632: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 213/213 [00:20<00:00, 10.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, loss: 0.6957057941127831\n",
            "Evaluating dev...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:02<00:00, 10.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev F1 0.5192307692307692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 213/213 [00:20<00:00, 10.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss: 0.6942554776657355\n",
            "Evaluating dev...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:02<00:00, 10.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev F1 0.5013975976429704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 213/213 [00:20<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2, loss: 0.693650203131734\n",
            "Evaluating dev...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:02<00:00, 10.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev F1 0.5095932657549482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 213/213 [00:21<00:00, 10.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3, loss: 0.6931214872660212\n",
            "Evaluating dev...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:02<00:00, 10.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev F1 0.5105830116804158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 213/213 [00:21<00:00, 10.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4, loss: 0.6926708912625559\n",
            "Evaluating dev...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:02<00:00, 10.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev F1 0.5114703734481629\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done training!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NLIClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28895, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (hidden_layer): Linear(in_features=768, out_features=512, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",
              "  (log_softmax): LogSoftmax(dim=2)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Get a final macro F1 on the test set.\n",
        "# You should be able to mimic what we did with the validaiton set.\n",
        "test_input_batches = [b for b in chunk_multi(test_premises, test_hypotheses, batch_size)]\n",
        "\n",
        "# Tokenize + encode\n",
        "test_input_batches = [batch_tokenizer(*batch) for batch in test_input_batches]\n",
        "test_batch_labels = [b for b in chunk(test_labels, batch_size)]\n",
        "test_batch_labels = [encode_labels(batch) for batch in test_batch_labels]\n",
        "\n",
        "test_preds = []\n",
        "test_labels = []\n",
        "for sents, labels in tqdm(zip(test_input_batches, test_batch_labels), total=len(test_input_batches)):\n",
        "    pred = predict(model, sents)\n",
        "    test_preds.extend(pred)\n",
        "    test_labels.extend(list(labels.cpu().numpy()))\n",
        "\n",
        "dev_f1 = macro_f1(test_preds, test_labels, possible_labels=[0,1])\n",
        "print(f\"Test F1 {dev_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_EU4mJd5wzp",
        "outputId": "c3b91548-07a4-463e-8c81-65e82c497258"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:02<00:00, 10.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test F1 0.5114703734481629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_labels, test_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRxnK8yZ5zTM",
        "outputId": "ed6c00e6-620d-4881-93e6-d3eeff8611b4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.43      0.47       100\n",
            "           1       0.51      0.60      0.55       100\n",
            "\n",
            "    accuracy                           0.52       200\n",
            "   macro avg       0.52      0.52      0.51       200\n",
            "weighted avg       0.52      0.52      0.51       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments with BiomedNLP-PubMedBERT"
      ],
      "metadata": {
        "id": "7S5Wq391oRH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##########ALTERNATE METHOD#############\n",
        "!pip install datasets\n",
        "!pip install accelerate -U\n",
        "#!pip install transformers -U\n",
        "#!pip install accelerate -U"
      ],
      "metadata": {
        "id": "m5OnZBqBXVbj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3efd1b64-c3ee-402f-a8e2-ed523b19ec59"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.15.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from datasets import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import transformers\n",
        "transformers.logging.set_verbosity_error()\n",
        "\n"
      ],
      "metadata": {
        "id": "Gv7ochwJZCIG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creation of custom dataset"
      ],
      "metadata": {
        "id": "YMvGBPwX0L1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=128):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            item['premise'],\n",
        "            item['hypothesis'],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        encoding['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'token_type_ids': encoding['token_type_ids'].squeeze(),\n",
        "            'labels': encoding['label']\n",
        "        }"
      ],
      "metadata": {
        "id": "pkIQCD0-0mjB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained PubMedBERT model and tokenizer\n",
        "model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n"
      ],
      "metadata": {
        "id": "FkdRNktl0rZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "064eda0d-a70c-4562-b3dd-9f938f6ae3b9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create instances of the datasets and dataloaders\n",
        "train_dataset_ = CustomDataset(train_dataset, tokenizer)\n",
        "val_dataset_ = CustomDataset(validation_dataset, tokenizer)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset_, batch_size=8, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset_, batch_size=8, shuffle=False)\n"
      ],
      "metadata": {
        "id": "l9LdhL1A0unK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop on Train and Validation set"
      ],
      "metadata": {
        "id": "6ME1qe050Gef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./pubmedbert-finetuned\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    save_steps=5000,\n",
        "    save_total_limit=2,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    learning_rate=2e-5,\n",
        "    gradient_accumulation_steps=1,\n",
        "    report_to=\"tensorboard\",\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "# Define the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=None,\n",
        "    train_dataset=train_dataset_,\n",
        "    eval_dataset=val_dataset_,\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the fine-tuned model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print the evaluation results\n",
        "print(results)\n",
        "\n"
      ],
      "metadata": {
        "id": "QCX514KTZU6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f295fc-716d-4b8e-b38d-615d405b5a64"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.6786, 'learning_rate': 1.6870109546165886e-05, 'epoch': 0.47}\n",
            "{'loss': 0.7196, 'learning_rate': 1.374021909233177e-05, 'epoch': 0.94}\n",
            "{'loss': 0.704, 'learning_rate': 1.0610328638497653e-05, 'epoch': 1.41}\n",
            "{'loss': 0.6971, 'learning_rate': 7.480438184663538e-06, 'epoch': 1.88}\n",
            "{'loss': 0.699, 'learning_rate': 4.350547730829422e-06, 'epoch': 2.35}\n",
            "{'eval_loss': 0.6905478835105896, 'eval_runtime': 1.6569, 'eval_samples_per_second': 120.708, 'eval_steps_per_second': 15.088, 'epoch': 2.35}\n",
            "{'loss': 0.696, 'learning_rate': 1.2206572769953053e-06, 'epoch': 2.82}\n",
            "{'train_runtime': 141.6011, 'train_samples_per_second': 36.017, 'train_steps_per_second': 4.513, 'train_loss': 0.6988333491652224, 'epoch': 3.0}\n",
            "{'eval_loss': 0.6898730397224426, 'eval_runtime': 1.6591, 'eval_samples_per_second': 120.545, 'eval_steps_per_second': 15.068, 'epoch': 3.0}\n",
            "{'eval_loss': 0.6898730397224426, 'eval_runtime': 1.6591, 'eval_samples_per_second': 120.545, 'eval_steps_per_second': 15.068, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, classification_report\n"
      ],
      "metadata": {
        "id": "2MrpZOQc1ymc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(trainer.evaluation_loop(dataloader=val_dataloader, description=\"eval\")[0], axis=1)"
      ],
      "metadata": {
        "id": "hhZF1C882MOd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = trainer.evaluation_loop(dataloader=val_dataloader, description=\"eval\")[1]"
      ],
      "metadata": {
        "id": "O0gSest-2-vP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
        "\n",
        "print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3op7Sky1v3T",
        "outputId": "6b68c0ca-7590-471b-914f-8fcad18a6b4f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.4756, Recall: 0.8478, F1 Score: 0.6094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlG3NIOrZtA0",
        "outputId": "04436d3c-d623-4eb3-c49e-fe7dceecf64d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.20      0.31        54\n",
            "           1       0.48      0.85      0.61        46\n",
            "\n",
            "    accuracy                           0.50       100\n",
            "   macro avg       0.54      0.53      0.46       100\n",
            "weighted avg       0.55      0.50      0.45       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation on test set"
      ],
      "metadata": {
        "id": "hmV279MC0nFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_ = CustomDataset(test_dataset, tokenizer)\n",
        "test_dataloader = DataLoader(test_dataset_, batch_size=8, shuffle=False)"
      ],
      "metadata": {
        "id": "iYKQkjsTcpNE"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=None,\n",
        "    train_dataset=train_dataset_,\n",
        "    eval_dataset=test_dataset_,\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the fine-tuned model\n",
        "results = trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NRU-aFKcxoO",
        "outputId": "b027a754-8bde-4939-eb67-f48e07e8139c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.5607, 'learning_rate': 1.6870109546165886e-05, 'epoch': 0.47}\n",
            "{'loss': 0.6842, 'learning_rate': 1.374021909233177e-05, 'epoch': 0.94}\n",
            "{'loss': 0.6602, 'learning_rate': 1.0610328638497653e-05, 'epoch': 1.41}\n",
            "{'loss': 0.6604, 'learning_rate': 7.480438184663538e-06, 'epoch': 1.88}\n",
            "{'loss': 0.6509, 'learning_rate': 4.350547730829422e-06, 'epoch': 2.35}\n",
            "{'eval_loss': 0.6791951060295105, 'eval_runtime': 1.9083, 'eval_samples_per_second': 104.807, 'eval_steps_per_second': 13.101, 'epoch': 2.35}\n",
            "{'loss': 0.6611, 'learning_rate': 1.2206572769953053e-06, 'epoch': 2.82}\n",
            "{'train_runtime': 143.4847, 'train_samples_per_second': 35.544, 'train_steps_per_second': 4.453, 'train_loss': 0.6472030723225529, 'epoch': 3.0}\n",
            "{'eval_loss': 0.6959329843521118, 'eval_runtime': 1.7293, 'eval_samples_per_second': 115.656, 'eval_steps_per_second': 14.457, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(trainer.evaluation_loop(dataloader=test_dataloader, description=\"eval\")[0], axis=1)\n",
        "y_true = trainer.evaluation_loop(dataloader=test_dataloader, description=\"eval\")[1]\n",
        "\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
        "\n",
        "print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNJR9NRadVsR",
        "outputId": "ebd453d3-fd07-4070-fb4d-779218dde651"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.4800, Recall: 0.7826, F1 Score: 0.5950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3XZIu3ydiT4",
        "outputId": "8b252b39-71f6-4e4e-d931-56350b4414ce"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.28      0.38        54\n",
            "           1       0.48      0.78      0.60        46\n",
            "\n",
            "    accuracy                           0.51       100\n",
            "   macro avg       0.54      0.53      0.49       100\n",
            "weighted avg       0.54      0.51      0.48       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "trainer.save_model(\"./pubmedbert-finetuned\")\n"
      ],
      "metadata": {
        "id": "3wovuCXl01Lr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7db3e6a74b4541299d0e4ea461ed7961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a63ab33da41c46fba3e9ac7b5f9ee858",
              "IPY_MODEL_b9c78124a54d47b8a70f2e22be41e5d7",
              "IPY_MODEL_1f045e21492f4208b4f5bf3a77edf5b3"
            ],
            "layout": "IPY_MODEL_cf52c0b0629846efbdbf9cbeb269b436"
          }
        },
        "a63ab33da41c46fba3e9ac7b5f9ee858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb5a0d9556be45c5815c581dcf98bf9e",
            "placeholder": "​",
            "style": "IPY_MODEL_c14a94f5b0b04f378bb6f71ba288846f",
            "value": "config.json: 100%"
          }
        },
        "b9c78124a54d47b8a70f2e22be41e5d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4417d79fd99d45fabbaccd4bda09abeb",
            "max": 559,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ba6b88df5e848279d9d48772cf8bea6",
            "value": 559
          }
        },
        "1f045e21492f4208b4f5bf3a77edf5b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08d5cbcf05e74c0289a86f9af1f81e87",
            "placeholder": "​",
            "style": "IPY_MODEL_7160d4b7f33d4c20a7f632b87bc7ce7c",
            "value": " 559/559 [00:00&lt;00:00, 35.0kB/s]"
          }
        },
        "cf52c0b0629846efbdbf9cbeb269b436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb5a0d9556be45c5815c581dcf98bf9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c14a94f5b0b04f378bb6f71ba288846f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4417d79fd99d45fabbaccd4bda09abeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ba6b88df5e848279d9d48772cf8bea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08d5cbcf05e74c0289a86f9af1f81e87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7160d4b7f33d4c20a7f632b87bc7ce7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c77aae91f454055a5644d1a742f648a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d370d3431dbc47bbb8aebc17da86952d",
              "IPY_MODEL_a52758c82e744a13923dcdfbe4ac1deb",
              "IPY_MODEL_957a94d2741b43e283a086dc34d88a45"
            ],
            "layout": "IPY_MODEL_0d4063d54bd149218626eae41ec0d7db"
          }
        },
        "d370d3431dbc47bbb8aebc17da86952d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a374ea57be646e09f074fac500d5edd",
            "placeholder": "​",
            "style": "IPY_MODEL_e31549bb58224eb198e9ff469ba9f24d",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "a52758c82e744a13923dcdfbe4ac1deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1c5b03133134df0a995fb78a9b40b4b",
            "max": 433019313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea4cccea489c45238371f62f2f15b94c",
            "value": 433019313
          }
        },
        "957a94d2741b43e283a086dc34d88a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25b9f3396c7e420b92447fd3d1ecc328",
            "placeholder": "​",
            "style": "IPY_MODEL_6d59dac1bdc741f69ded63cf3f5f5e2f",
            "value": " 433M/433M [00:12&lt;00:00, 31.3MB/s]"
          }
        },
        "0d4063d54bd149218626eae41ec0d7db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a374ea57be646e09f074fac500d5edd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e31549bb58224eb198e9ff469ba9f24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1c5b03133134df0a995fb78a9b40b4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea4cccea489c45238371f62f2f15b94c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25b9f3396c7e420b92447fd3d1ecc328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d59dac1bdc741f69ded63cf3f5f5e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}